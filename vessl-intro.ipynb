{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a05d1142",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img height=\"80\" src=\"https://miro.medium.com/max/198/1*-ZlGSSXvRbDSr13_CDRaJA.png\">\n",
    "<p style=\"text-align:center\">Accelerate the development of ML applications with modern workflow.<br>\n",
    "Go from experiments to real-world applications faster at scale.<br>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "    <a target=\"_blank\" href=\"https://join.slack.com/t/vessl-ai-community/shared_invite/zt-1a6schu04-NyjRKE0UMli58Z_lthBICA\"><img src=\"https://img.shields.io/badge/style--5eba00.svg?label=Slack&logo=slack&style=social\"></a>&nbsp;\n",
    "    <a target=\"_blank\" href=\"https://twitter.com/vesslai\"><img src=\"https://img.shields.io/badge/style--5eba00.svg?label=Twitter&logo=twitter&style=social\"></a>&nbsp;\n",
    "    <a target=\"_blank\" href=\"https://www.linkedin.com/company/vesslai\"><img src=\"https://img.shields.io/badge/style--5eba00.svg?label=LinkedIn&logo=linkedin&style=social\"></a>&nbsp;\n",
    "    <a target=\"_blank\" href=\"https://vesslai.medium.com/\"><img src=\"https://img.shields.io/badge/style--5eba00.svg?label=Medium&logo=medium&style=social\"></a>&nbsp;\n",
    "    <a target=\"_blank\" href=\"https://github.com/vessl-ai/examples/\"><img src=\"https://img.shields.io/badge/style--5eba00.svg?label=GitHub&logo=github&style=social\"></a>&nbsp;\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ee7680",
   "metadata": {},
   "source": [
    "## Quickstart\n",
    " \n",
    "**Use VESSL Workspace to build models from scratch** <br>\n",
    "‚ö° &nbsp; Get instant access to GPU-accelerated Jupyter notebook <br>\n",
    "üéõÔ∏è &nbsp; Jump right into pre-configured dev environment shared across your team <br>\n",
    "üìà &nbsp; log and visualize experiments a dashboard with `vessl` library<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb67468a",
   "metadata": {},
   "source": [
    "## 1. Install `vessl` library and login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918eb268",
   "metadata": {},
   "source": [
    "All notebooks created on VESSL Workspace come with the latest version of `vessl` library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e84178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current version of vessl\n",
    "!vessl --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f736fc08",
   "metadata": {},
   "source": [
    "Let's start by logging into your account and configuring your organization and project. This designates where your experiments will be recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db70c6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new project to run this example\n",
    "import datetime\n",
    "import vessl\n",
    "\n",
    "project_name = f\"vessl-example-{int(datetime.datetime.now().timestamp())}\"\n",
    "vessl.create_project(project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f9f124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure default project\n",
    "vessl.configure(project_name=project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b594de",
   "metadata": {},
   "source": [
    "These notebooks also come with essential ML libraries like `matplotlib` and `torch` pre-installed, which you can view by `pip list` or using the `watermark` library. You can configure these default libraries by [üîó&nbsp; building custom Docker images](https://docs.vessl.ai/user-guide/workspace/building-custom-images#building-from-community-maintained-images) for your team. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aeabd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!pip list\n",
    "\n",
    "# Show the current versions of the pre-installed libraries\n",
    "!!pip install watermark\n",
    "import watermark\n",
    "%load_ext watermark\n",
    "%watermark -v -p numpy,matplotlib,torch,torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7679be45",
   "metadata": {},
   "source": [
    "Before moving on to our dataset and model, let's import these libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c49e725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "%pylab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a2c227",
   "metadata": {},
   "source": [
    "## 2. Prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f7bfa1",
   "metadata": {},
   "source": [
    "In this example, we will train an image classification model using the [üîó&nbsp; MNIST dataset](https://paperswithcode.com/dataset/mnist). Here, we will use the publicly available dataset from `torchvision`. You can also mount a volume and import your own datasets using [üîó&nbsp; VESSL Dataset](https://docs.vessl.ai/user-guide/dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8bf61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the MNIST training data\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "train_data = datasets.MNIST(\n",
    "    root = '/tmp/example-data',\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    "    download = True,            \n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = '/tmp/example-data', \n",
    "    train = False, \n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "# Downsize the dataset to run fast.\n",
    "train_data.data = train_data.data[:200]\n",
    "test_data.data = test_data.data[:1000]\n",
    "print(f'The shape of train data: {train_data.data.shape}')\n",
    "print(f'The shape of test data: {test_data.data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da6ed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render sample images from the training data\n",
    "figure = plt.figure(figsize=(10, 8))\n",
    "cols, rows = 5, 1\n",
    "\n",
    "for i in range(1, cols*rows + 1):\n",
    "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
    "    img, label = train_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52795305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True, num_workers=1)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba07a4ff",
   "metadata": {},
   "source": [
    "## 3. Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92425b5b",
   "metadata": {},
   "source": [
    "Let's define an image classification model using a simple two-dimensional convolutional neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ffd99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.drop1 = nn.Dropout2d(0.25)\n",
    "        self.drop2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.softmax = nn.LogSoftmax(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.drop1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.fc2(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9381ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN().to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a8e408",
   "metadata": {},
   "source": [
    "## 4. Use `vessl.log()` to log and visualize experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75027e95",
   "metadata": {},
   "source": [
    "Now that we have the dataset and model ready, the next step is to write a script for training and testing the model. With VESSL, you can record outputs from your experiments such as key metrics and media files. Store, visualize, and compare experiment results using [üîó&nbsp; `vessl.log()`](https://docs.vessl.ai/api-reference/python-sdk/utils/vessl.log)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedc70d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train function with VESSL logging\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, start_epoch):\n",
    "    model.train()\n",
    "    loss = 0\n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 128 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch + 1, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch + 1, len(train_loader.dataset), len(train_loader.dataset), 100, loss.item()))\n",
    "\n",
    "    # Logging loss metrics to Vessl\n",
    "    vessl.log(\n",
    "        step=epoch + start_epoch + 1,\n",
    "        payload={'loss': loss.item()}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9baf27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function (with vessl plot uploading)\n",
    "def test(model, device, test_loader, save_image):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    test_images = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            test_images.append(vessl.Image(\n",
    "                data[0], caption=\"Pred: {} Truth: {}\".format(pred[0].item(), target[0])))\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), test_accuracy))\n",
    "\n",
    "    # Saving inference results with caption into Vessl\n",
    "    if save_image:\n",
    "        vessl.log({\"Examples\": test_images})\n",
    "\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a2d6c7",
   "metadata": {},
   "source": [
    "## 5. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd71c047",
   "metadata": {},
   "source": [
    "Let's run the experiment. [üîó&nbsp; `vessl.init()`](https://docs.vessl.ai/api-reference/python-sdk/utils/vessl.init) creates a new experiment and our Python SDK will automatically record all metrics and logs on the the newly created experiment. You can check the progress on VESSL by visiting the output link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7962b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize new experiment via VESSL SDK \n",
    "vessl.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538c3671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(epochs):\n",
    "    train(model, device, train_loader, optimizer, epoch, 0)\n",
    "    test(model, device, test_loader, True)\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a29f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish experiment\n",
    "vessl.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b1d3a2",
   "metadata": {},
   "source": [
    "## What's next\n",
    "\n",
    "**Try `vessl run`** <br>\n",
    "Just add `vessl run` before your command to run the process on VESSL infrastructure. <br>\n",
    "Try `vessl run python vessl-example-mnist.py` on terminal.\n",
    "\n",
    "\n",
    "**Use VESSL Experiments to orchestrate experiments and optimize your model** <br>\n",
    "ü™Ñ &nbsp; Orchestrate multiple experiments in parallel using [üîó&nbsp; VESSL experiments](https://docs.vessl.ai/user-guide/experiment) <br>\n",
    "üèÉ &nbsp; Move seemlessly between local, cloud, and on-premise servers using [üîó&nbsp; `vessl run`](https://docs.vessl.ai/api-reference/cli/vessl-run#overview) <br>\n",
    "üî• &nbsp; Optimize your model using [üîó&nbsp; hyperparameter optimization](https://docs.vessl.ai/user-guide/sweep) and [üîó&nbsp; distributed training](https://docs.vessl.ai/user-guide/experiment/distributed-experiments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Full on Python 3.6 (CPU-only)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
